{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import skimage\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Dense, Dropout,Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import animation\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opticalFlowDense(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    calculates optical flow magnitude and angle and places it into HSV image\n",
    "    * Set the saturation to the saturation value of image_next\n",
    "    * Set the hue to the angles returned from computing the flow params\n",
    "    * set the value to the magnitude returned from computing the flow params\n",
    "    * Convert from HSV to RGB and return RGB image with same size as original image\n",
    "    \"\"\"\n",
    "    h,w = image_current.shape\n",
    "    hsv = np.zeros((h,w,3)).astype(np.uint8)\n",
    "    hsv[...,1] = 255\n",
    "    \n",
    "    flow = cv2.calcOpticalFlowFarneback(image_current,image_next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    hsv[...,0] = ang*180/np.pi/2\n",
    "    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return rgb\n",
    "def plot_movie(image_array):\n",
    "    dpi = 72.0\n",
    "    xpixels, ypixels = image_array[0].shape[0], image_array[0].shape[1]\n",
    "    fig = plt.figure(figsize=(ypixels/dpi, xpixels/dpi), dpi=dpi)\n",
    "    im = plt.figimage(image_array[0])\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_array(image_array[i])\n",
    "        return (im,)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=len(image_array))\n",
    "    display(HTML(anim.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_PAIR_DELTA_MS = 300\n",
    "IMG_HEIGHT = 720//4\n",
    "IMG_WIDTH = 1080//4\n",
    "TOTAL_TO_PROCESS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob('val/info/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_path = info_paths[886]\n",
    "\n",
    "with open(info_path) as f:\n",
    "        info = json.load(f)\n",
    "info_df = pd.DataFrame(info['locations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('data/info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26604\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for index, row in y.iterrows():\n",
    "    print(len(y))\n",
    "    y = y.drop(index)\n",
    "#     try:\n",
    "    img = cv2.imread(row['path'])\n",
    "    X.append(img)#cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_AREA))\n",
    "#     except:\n",
    "#         y.drop(index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1000\n",
      "2/1000\n",
      "3/1000\n",
      "4/1000\n",
      "5/1000\n",
      "6/1000\n",
      "7/1000\n",
      "8/1000\n",
      "9/1000\n",
      "10/1000\n",
      "11/1000\n",
      "12/1000\n",
      "13/1000\n",
      "14/1000\n",
      "15/1000\n",
      "16/1000\n",
      "17/1000\n",
      "18/1000\n",
      "19/1000\n",
      "20/1000\n",
      "21/1000\n",
      "22/1000\n",
      "23/1000\n",
      "24/1000\n",
      "25/1000\n",
      "26/1000\n",
      "27/1000\n",
      "28/1000\n",
      "29/1000\n",
      "30/1000\n",
      "31/1000\n",
      "32/1000\n",
      "33/1000\n",
      "34/1000\n",
      "35/1000\n",
      "36/1000\n",
      "37/1000\n",
      "38/1000\n",
      "39/1000\n",
      "40/1000\n",
      "41/1000\n",
      "42/1000\n",
      "43/1000\n",
      "44/1000\n",
      "45/1000\n",
      "46/1000\n",
      "47/1000\n",
      "48/1000\n",
      "49/1000\n",
      "50/1000\n",
      "51/1000\n",
      "52/1000\n",
      "53/1000\n",
      "54/1000\n",
      "55/1000\n",
      "56/1000\n",
      "57/1000\n",
      "58/1000\n",
      "59/1000\n",
      "60/1000\n",
      "61/1000\n",
      "62/1000\n",
      "63/1000\n",
      "64/1000\n",
      "65/1000\n",
      "66/1000\n",
      "67/1000\n",
      "68/1000\n",
      "69/1000\n",
      "70/1000\n",
      "71/1000\n",
      "72/1000\n",
      "73/1000\n",
      "74/1000\n",
      "75/1000\n",
      "76/1000\n",
      "77/1000\n",
      "78/1000\n",
      "79/1000\n",
      "80/1000\n",
      "81/1000\n",
      "82/1000\n",
      "83/1000\n",
      "84/1000\n",
      "85/1000\n",
      "86/1000\n",
      "87/1000\n",
      "88/1000\n",
      "89/1000\n",
      "90/1000\n",
      "91/1000\n",
      "92/1000\n",
      "93/1000\n",
      "94/1000\n",
      "95/1000\n",
      "96/1000\n",
      "97/1000\n",
      "98/1000\n",
      "99/1000\n",
      "100/1000\n",
      "101/1000\n",
      "102/1000\n",
      "103/1000\n",
      "104/1000\n",
      "105/1000\n",
      "106/1000\n",
      "107/1000\n",
      "108/1000\n",
      "109/1000\n",
      "110/1000\n",
      "111/1000\n",
      "112/1000\n",
      "113/1000\n",
      "114/1000\n",
      "115/1000\n",
      "116/1000\n",
      "117/1000\n",
      "118/1000\n",
      "119/1000\n",
      "120/1000\n",
      "121/1000\n",
      "122/1000\n",
      "123/1000\n",
      "124/1000\n",
      "125/1000\n",
      "126/1000\n",
      "127/1000\n",
      "128/1000\n",
      "129/1000\n",
      "130/1000\n",
      "131/1000\n",
      "132/1000\n",
      "133/1000\n",
      "134/1000\n",
      "135/1000\n",
      "136/1000\n",
      "137/1000\n",
      "138/1000\n",
      "139/1000\n",
      "140/1000\n",
      "141/1000\n",
      "142/1000\n",
      "143/1000\n",
      "144/1000\n",
      "145/1000\n",
      "146/1000\n",
      "147/1000\n",
      "148/1000\n",
      "149/1000\n",
      "150/1000\n",
      "151/1000\n",
      "152/1000\n",
      "153/1000\n",
      "154/1000\n",
      "155/1000\n",
      "156/1000\n",
      "157/1000\n",
      "158/1000\n",
      "159/1000\n",
      "160/1000\n",
      "161/1000\n",
      "162/1000\n",
      "163/1000\n",
      "164/1000\n",
      "165/1000\n",
      "166/1000\n",
      "167/1000\n",
      "168/1000\n",
      "169/1000\n",
      "170/1000\n",
      "171/1000\n",
      "172/1000\n",
      "173/1000\n",
      "174/1000\n",
      "175/1000\n",
      "176/1000\n",
      "177/1000\n",
      "178/1000\n",
      "179/1000\n",
      "180/1000\n",
      "181/1000\n",
      "182/1000\n",
      "183/1000\n",
      "184/1000\n",
      "185/1000\n",
      "186/1000\n",
      "187/1000\n",
      "188/1000\n",
      "189/1000\n",
      "190/1000\n",
      "191/1000\n",
      "192/1000\n",
      "193/1000\n",
      "194/1000\n",
      "195/1000\n",
      "196/1000\n",
      "197/1000\n",
      "198/1000\n",
      "199/1000\n",
      "200/1000\n",
      "201/1000\n",
      "202/1000\n",
      "203/1000\n",
      "204/1000\n",
      "205/1000\n",
      "206/1000\n",
      "207/1000\n",
      "208/1000\n",
      "209/1000\n",
      "210/1000\n",
      "211/1000\n",
      "212/1000\n",
      "213/1000\n",
      "214/1000\n",
      "215/1000\n",
      "216/1000\n",
      "217/1000\n",
      "218/1000\n",
      "219/1000\n",
      "220/1000\n",
      "221/1000\n",
      "222/1000\n",
      "223/1000\n",
      "224/1000\n",
      "225/1000\n",
      "226/1000\n",
      "227/1000\n",
      "228/1000\n",
      "229/1000\n",
      "230/1000\n",
      "231/1000\n",
      "232/1000\n",
      "233/1000\n",
      "234/1000\n",
      "235/1000\n",
      "236/1000\n",
      "237/1000\n",
      "238/1000\n",
      "239/1000\n",
      "240/1000\n",
      "241/1000\n",
      "242/1000\n",
      "243/1000\n",
      "244/1000\n",
      "245/1000\n",
      "246/1000\n",
      "247/1000\n",
      "248/1000\n",
      "249/1000\n",
      "250/1000\n",
      "251/1000\n",
      "252/1000\n",
      "253/1000\n",
      "254/1000\n",
      "255/1000\n",
      "256/1000\n",
      "257/1000\n",
      "258/1000\n",
      "259/1000\n",
      "260/1000\n",
      "261/1000\n",
      "262/1000\n",
      "263/1000\n",
      "264/1000\n",
      "265/1000\n",
      "266/1000\n",
      "267/1000\n",
      "268/1000\n",
      "269/1000\n",
      "270/1000\n",
      "271/1000\n",
      "272/1000\n",
      "273/1000\n",
      "274/1000\n",
      "275/1000\n",
      "276/1000\n",
      "277/1000\n",
      "278/1000\n",
      "279/1000\n",
      "280/1000\n",
      "281/1000\n",
      "282/1000\n",
      "283/1000\n",
      "284/1000\n",
      "285/1000\n",
      "286/1000\n",
      "287/1000\n",
      "288/1000\n",
      "289/1000\n",
      "290/1000\n",
      "291/1000\n",
      "292/1000\n",
      "293/1000\n",
      "294/1000\n",
      "295/1000\n",
      "296/1000\n",
      "297/1000\n",
      "298/1000\n",
      "299/1000\n",
      "300/1000\n",
      "301/1000\n",
      "302/1000\n",
      "303/1000\n",
      "304/1000\n",
      "305/1000\n",
      "306/1000\n",
      "307/1000\n",
      "308/1000\n",
      "309/1000\n",
      "310/1000\n",
      "311/1000\n",
      "312/1000\n",
      "313/1000\n",
      "314/1000\n",
      "315/1000\n",
      "316/1000\n",
      "317/1000\n",
      "318/1000\n",
      "319/1000\n",
      "320/1000\n",
      "321/1000\n",
      "322/1000\n",
      "323/1000\n",
      "324/1000\n",
      "325/1000\n",
      "326/1000\n",
      "327/1000\n",
      "328/1000\n",
      "329/1000\n",
      "330/1000\n",
      "331/1000\n",
      "332/1000\n",
      "333/1000\n",
      "334/1000\n",
      "335/1000\n",
      "336/1000\n",
      "337/1000\n",
      "338/1000\n",
      "339/1000\n",
      "340/1000\n",
      "341/1000\n",
      "342/1000\n",
      "343/1000\n",
      "344/1000\n",
      "345/1000\n",
      "346/1000\n",
      "347/1000\n",
      "348/1000\n",
      "349/1000\n",
      "350/1000\n",
      "351/1000\n",
      "352/1000\n",
      "353/1000\n",
      "354/1000\n",
      "355/1000\n",
      "356/1000\n",
      "357/1000\n",
      "358/1000\n",
      "359/1000\n",
      "360/1000\n",
      "361/1000\n",
      "362/1000\n",
      "363/1000\n",
      "364/1000\n",
      "365/1000\n",
      "366/1000\n",
      "367/1000\n",
      "368/1000\n",
      "369/1000\n",
      "370/1000\n",
      "371/1000\n",
      "372/1000\n",
      "373/1000\n",
      "374/1000\n",
      "375/1000\n",
      "376/1000\n",
      "377/1000\n",
      "378/1000\n",
      "379/1000\n",
      "380/1000\n",
      "381/1000\n",
      "382/1000\n",
      "383/1000\n",
      "384/1000\n",
      "385/1000\n",
      "386/1000\n",
      "387/1000\n",
      "388/1000\n",
      "389/1000\n",
      "390/1000\n",
      "391/1000\n",
      "392/1000\n",
      "393/1000\n",
      "394/1000\n",
      "395/1000\n",
      "396/1000\n",
      "397/1000\n",
      "398/1000\n",
      "399/1000\n",
      "400/1000\n",
      "401/1000\n",
      "402/1000\n",
      "403/1000\n",
      "404/1000\n",
      "405/1000\n",
      "406/1000\n",
      "407/1000\n",
      "408/1000\n",
      "409/1000\n",
      "410/1000\n",
      "411/1000\n",
      "412/1000\n",
      "413/1000\n",
      "414/1000\n",
      "415/1000\n",
      "416/1000\n",
      "417/1000\n",
      "418/1000\n",
      "419/1000\n",
      "420/1000\n",
      "421/1000\n",
      "422/1000\n",
      "423/1000\n",
      "424/1000\n",
      "425/1000\n",
      "426/1000\n",
      "427/1000\n",
      "428/1000\n",
      "429/1000\n",
      "430/1000\n",
      "431/1000\n",
      "432/1000\n",
      "433/1000\n",
      "434/1000\n",
      "435/1000\n",
      "436/1000\n",
      "437/1000\n",
      "438/1000\n",
      "439/1000\n",
      "440/1000\n",
      "441/1000\n",
      "442/1000\n",
      "443/1000\n",
      "444/1000\n",
      "445/1000\n",
      "446/1000\n",
      "447/1000\n",
      "448/1000\n",
      "449/1000\n",
      "450/1000\n",
      "451/1000\n",
      "452/1000\n",
      "453/1000\n",
      "454/1000\n",
      "455/1000\n",
      "456/1000\n",
      "457/1000\n",
      "458/1000\n",
      "459/1000\n",
      "460/1000\n",
      "461/1000\n",
      "462/1000\n",
      "463/1000\n",
      "464/1000\n",
      "465/1000\n",
      "466/1000\n",
      "467/1000\n",
      "468/1000\n",
      "469/1000\n",
      "470/1000\n",
      "471/1000\n",
      "472/1000\n",
      "473/1000\n",
      "474/1000\n",
      "475/1000\n",
      "476/1000\n",
      "477/1000\n",
      "478/1000\n",
      "479/1000\n",
      "480/1000\n",
      "481/1000\n",
      "482/1000\n",
      "483/1000\n",
      "484/1000\n",
      "485/1000\n",
      "486/1000\n",
      "487/1000\n",
      "488/1000\n",
      "489/1000\n",
      "490/1000\n",
      "491/1000\n",
      "492/1000\n",
      "493/1000\n",
      "494/1000\n",
      "495/1000\n",
      "496/1000\n",
      "497/1000\n",
      "498/1000\n",
      "499/1000\n",
      "500/1000\n",
      "501/1000\n",
      "502/1000\n",
      "503/1000\n",
      "504/1000\n",
      "505/1000\n",
      "506/1000\n",
      "507/1000\n",
      "508/1000\n",
      "509/1000\n",
      "510/1000\n",
      "511/1000\n",
      "512/1000\n",
      "513/1000\n",
      "514/1000\n",
      "515/1000\n",
      "516/1000\n",
      "517/1000\n",
      "518/1000\n",
      "519/1000\n",
      "520/1000\n",
      "521/1000\n",
      "522/1000\n",
      "523/1000\n",
      "524/1000\n",
      "525/1000\n",
      "526/1000\n",
      "527/1000\n",
      "528/1000\n",
      "529/1000\n",
      "530/1000\n",
      "531/1000\n",
      "532/1000\n",
      "533/1000\n",
      "534/1000\n",
      "535/1000\n",
      "536/1000\n",
      "537/1000\n",
      "538/1000\n",
      "539/1000\n",
      "540/1000\n",
      "541/1000\n",
      "542/1000\n",
      "543/1000\n",
      "544/1000\n",
      "545/1000\n",
      "546/1000\n",
      "547/1000\n",
      "548/1000\n",
      "549/1000\n",
      "550/1000\n",
      "551/1000\n",
      "552/1000\n",
      "553/1000\n",
      "554/1000\n",
      "555/1000\n",
      "556/1000\n",
      "557/1000\n",
      "558/1000\n",
      "559/1000\n",
      "560/1000\n",
      "561/1000\n",
      "562/1000\n",
      "563/1000\n",
      "564/1000\n",
      "565/1000\n",
      "566/1000\n",
      "567/1000\n",
      "568/1000\n",
      "569/1000\n",
      "570/1000\n",
      "571/1000\n",
      "572/1000\n",
      "573/1000\n",
      "574/1000\n",
      "575/1000\n",
      "576/1000\n",
      "577/1000\n",
      "578/1000\n",
      "579/1000\n",
      "580/1000\n",
      "581/1000\n",
      "582/1000\n",
      "583/1000\n",
      "584/1000\n",
      "585/1000\n",
      "586/1000\n",
      "587/1000\n",
      "588/1000\n",
      "589/1000\n",
      "590/1000\n",
      "591/1000\n",
      "592/1000\n",
      "593/1000\n",
      "594/1000\n",
      "595/1000\n",
      "596/1000\n",
      "597/1000\n",
      "598/1000\n",
      "599/1000\n",
      "600/1000\n",
      "601/1000\n",
      "602/1000\n",
      "603/1000\n",
      "604/1000\n",
      "605/1000\n",
      "606/1000\n",
      "607/1000\n",
      "608/1000\n",
      "609/1000\n",
      "610/1000\n",
      "611/1000\n",
      "612/1000\n",
      "613/1000\n",
      "614/1000\n",
      "615/1000\n",
      "616/1000\n",
      "617/1000\n",
      "618/1000\n",
      "619/1000\n",
      "620/1000\n",
      "621/1000\n",
      "622/1000\n",
      "623/1000\n",
      "624/1000\n",
      "625/1000\n",
      "626/1000\n",
      "627/1000\n",
      "628/1000\n",
      "629/1000\n",
      "630/1000\n",
      "631/1000\n",
      "632/1000\n",
      "633/1000\n",
      "634/1000\n",
      "635/1000\n",
      "636/1000\n",
      "637/1000\n",
      "638/1000\n",
      "639/1000\n",
      "640/1000\n",
      "641/1000\n",
      "642/1000\n",
      "643/1000\n",
      "644/1000\n",
      "645/1000\n",
      "646/1000\n",
      "647/1000\n",
      "648/1000\n",
      "649/1000\n",
      "650/1000\n",
      "651/1000\n",
      "652/1000\n",
      "653/1000\n",
      "654/1000\n",
      "655/1000\n",
      "656/1000\n",
      "657/1000\n",
      "658/1000\n",
      "659/1000\n",
      "660/1000\n",
      "661/1000\n",
      "662/1000\n",
      "663/1000\n",
      "664/1000\n",
      "665/1000\n",
      "666/1000\n",
      "667/1000\n",
      "668/1000\n",
      "669/1000\n",
      "670/1000\n",
      "671/1000\n",
      "672/1000\n",
      "673/1000\n",
      "674/1000\n",
      "675/1000\n",
      "676/1000\n",
      "677/1000\n",
      "678/1000\n",
      "679/1000\n",
      "680/1000\n",
      "681/1000\n",
      "682/1000\n",
      "683/1000\n",
      "684/1000\n",
      "685/1000\n",
      "686/1000\n",
      "687/1000\n",
      "688/1000\n",
      "689/1000\n",
      "690/1000\n",
      "691/1000\n",
      "692/1000\n",
      "693/1000\n",
      "694/1000\n",
      "695/1000\n",
      "696/1000\n",
      "697/1000\n",
      "698/1000\n",
      "699/1000\n",
      "700/1000\n",
      "701/1000\n",
      "702/1000\n",
      "712/1000\n",
      "713/1000\n",
      "714/1000\n",
      "715/1000\n",
      "716/1000\n",
      "717/1000\n",
      "718/1000\n",
      "719/1000\n",
      "720/1000\n",
      "721/1000\n",
      "722/1000\n",
      "723/1000\n",
      "724/1000\n",
      "725/1000\n",
      "726/1000\n",
      "727/1000\n",
      "728/1000\n",
      "729/1000\n",
      "730/1000\n",
      "731/1000\n",
      "732/1000\n",
      "733/1000\n",
      "734/1000\n",
      "735/1000\n",
      "736/1000\n",
      "737/1000\n",
      "738/1000\n",
      "739/1000\n",
      "740/1000\n",
      "741/1000\n",
      "742/1000\n",
      "743/1000\n",
      "744/1000\n",
      "745/1000\n",
      "746/1000\n",
      "747/1000\n",
      "748/1000\n",
      "749/1000\n",
      "750/1000\n",
      "751/1000\n",
      "752/1000\n",
      "753/1000\n",
      "754/1000\n",
      "755/1000\n",
      "756/1000\n",
      "757/1000\n",
      "758/1000\n",
      "759/1000\n",
      "760/1000\n",
      "761/1000\n",
      "762/1000\n",
      "763/1000\n",
      "764/1000\n",
      "765/1000\n",
      "766/1000\n",
      "767/1000\n",
      "768/1000\n",
      "769/1000\n",
      "770/1000\n",
      "771/1000\n",
      "772/1000\n",
      "773/1000\n",
      "774/1000\n",
      "775/1000\n",
      "776/1000\n",
      "777/1000\n",
      "778/1000\n",
      "779/1000\n",
      "780/1000\n",
      "781/1000\n",
      "782/1000\n",
      "783/1000\n",
      "784/1000\n",
      "785/1000\n",
      "786/1000\n",
      "787/1000\n",
      "788/1000\n",
      "789/1000\n",
      "790/1000\n",
      "791/1000\n",
      "792/1000\n",
      "793/1000\n",
      "794/1000\n",
      "795/1000\n",
      "796/1000\n",
      "797/1000\n",
      "798/1000\n",
      "799/1000\n",
      "800/1000\n",
      "801/1000\n",
      "802/1000\n",
      "803/1000\n",
      "804/1000\n",
      "805/1000\n",
      "806/1000\n",
      "807/1000\n",
      "808/1000\n",
      "809/1000\n",
      "810/1000\n",
      "811/1000\n",
      "812/1000\n",
      "813/1000\n",
      "814/1000\n",
      "815/1000\n",
      "816/1000\n",
      "817/1000\n",
      "818/1000\n",
      "819/1000\n",
      "820/1000\n",
      "821/1000\n",
      "822/1000\n",
      "823/1000\n",
      "824/1000\n",
      "825/1000\n",
      "826/1000\n",
      "827/1000\n",
      "828/1000\n",
      "829/1000\n",
      "830/1000\n",
      "831/1000\n",
      "832/1000\n",
      "833/1000\n",
      "834/1000\n",
      "835/1000\n",
      "836/1000\n",
      "837/1000\n",
      "838/1000\n",
      "839/1000\n",
      "840/1000\n",
      "841/1000\n",
      "842/1000\n",
      "843/1000\n",
      "844/1000\n",
      "845/1000\n",
      "846/1000\n",
      "847/1000\n",
      "848/1000\n",
      "849/1000\n",
      "850/1000\n",
      "851/1000\n",
      "852/1000\n",
      "853/1000\n",
      "854/1000\n",
      "855/1000\n",
      "856/1000\n",
      "857/1000\n",
      "858/1000\n",
      "859/1000\n",
      "860/1000\n",
      "861/1000\n",
      "862/1000\n",
      "863/1000\n",
      "864/1000\n",
      "865/1000\n",
      "866/1000\n",
      "867/1000\n",
      "868/1000\n",
      "869/1000\n",
      "870/1000\n",
      "871/1000\n",
      "872/1000\n",
      "873/1000\n",
      "874/1000\n",
      "875/1000\n",
      "876/1000\n",
      "877/1000\n",
      "878/1000\n",
      "879/1000\n",
      "880/1000\n",
      "881/1000\n",
      "882/1000\n",
      "883/1000\n",
      "884/1000\n",
      "885/1000\n",
      "886/1000\n",
      "887/1000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2655\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2656\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2657\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-4e140cdd66e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minfo_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'locations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0minfo_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#     print('Reading {}...'.format(vid_path))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "# X = []\n",
    "y = []\n",
    "info_paths = sorted(glob.glob('data/info/*'))[:TOTAL_TO_PROCESS]\n",
    "i = 1\n",
    "for info_path in info_paths:\n",
    "    print('{}/{}'.format(i, TOTAL_TO_PROCESS))\n",
    "    vid_path = info_path.replace('info','videos').replace('.json','.mov')\n",
    "    with open(info_path) as f:\n",
    "        info = json.load(f)\n",
    "    info_df = pd.DataFrame(info['locations'])\n",
    "    info_df['timestamp'] -= min(info_df['timestamp'])\n",
    "    vid = cv2.VideoCapture(vid_path)\n",
    "#     print('Reading {}...'.format(vid_path))\n",
    "    last_idx = len(info_df) - 1\n",
    "    for index, row in info_df.iterrows():\n",
    "        if index == 0:\n",
    "            continue\n",
    "        timestamp = row['timestamp']\n",
    "        vid.set(cv2.CAP_PROP_POS_MSEC, timestamp)\n",
    "        success, frame = vid.read()\n",
    "        vid.set(cv2.CAP_PROP_POS_MSEC, timestamp + FRAME_PAIR_DELTA_MS)\n",
    "        next_success, next_frame = vid.read()\n",
    "        if next_success:\n",
    "            # generate flow image\n",
    "            frame = np.rot90(cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY),axes=(1,0))\n",
    "            frame = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_AREA)\n",
    "            next_frame = np.rot90(cv2.cvtColor(next_frame,cv2.COLOR_BGR2GRAY),axes=(1,0))\n",
    "            next_frame = cv2.resize(next_frame, (IMG_WIDTH, IMG_HEIGHT), interpolation = cv2.INTER_AREA)\n",
    "            flow = opticalFlowDense(frame, next_frame)\n",
    "            flow_filename = 'data/train/flow/{}_{}.jpg'.format(vid_path.split('/')[-1][:-4],timestamp)\n",
    "            cv2.imwrite(flow_filename, flow)\n",
    "            \n",
    "#             X.append(flow)\n",
    "            # compute gps delta \n",
    "            lat_delta = (info_df.loc[index]['latitude'] - info_df.loc[index-1]['latitude'])*100000\n",
    "            lon_delta = (info_df.loc[index]['longitude'] - info_df.loc[index-1]['longitude'])*100000\n",
    "            speed = info_df.loc[index]['speed']\n",
    "            y.append(np.array((lat_delta, lon_delta, speed)))\n",
    "    i += 1\n",
    "pd.DataFrame(y).to_csv('data/train/info.csv', index=False)\n",
    "print('{} samples processed'.format(len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_path = sorted(glob.glob('data/train/images/*'))\n",
    "X = []\n",
    "for img_path in preprocessed_path:\n",
    "    img = cv2.imread(img_path)\n",
    "    X.append(img)\n",
    "y = pd.read_csv('data/train/info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30942"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.read_csv('data/train/info.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputShape = X[0].shape\n",
    "\n",
    "model = Sequential()\n",
    "# normalization    \n",
    "# perform custom normalization before lambda layer in network\n",
    "model.add(Lambda(lambda x: x/ 127.5 - 1, input_shape = inputShape))\n",
    "model.add(Convolution2D(24, (5, 5), \n",
    "                        strides=(2,2), \n",
    "                        padding = 'valid',\n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        name = 'conv1'))\n",
    "model.add(ELU())    \n",
    "model.add(Convolution2D(36, (5, 5), \n",
    "                        strides=(2,2), \n",
    "                        padding = 'valid',\n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        name = 'conv2'))\n",
    "model.add(ELU())    \n",
    "model.add(Convolution2D(48, (5, 5), \n",
    "                        strides=(2,2), \n",
    "                        padding = 'valid',\n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        name = 'conv3'))\n",
    "model.add(ELU())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(64, (3, 3), \n",
    "                        strides = (1,1), \n",
    "                        padding = 'valid',\n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        name = 'conv4'))\n",
    "model.add(ELU())              \n",
    "model.add(Convolution2D(64, (3, 3), \n",
    "                        strides= (1,1), \n",
    "                        padding = 'valid',\n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        name = 'conv5'))\n",
    "model.add(Flatten(name = 'flatten'))\n",
    "model.add(ELU())\n",
    "model.add(Dense(100, kernel_initializer = 'he_normal', name = 'fc1'))\n",
    "model.add(ELU())\n",
    "model.add(Dense(50, kernel_initializer = 'he_normal', name = 'fc2'))\n",
    "model.add(ELU())\n",
    "model.add(Dense(10, kernel_initializer = 'he_normal', name = 'fc3'))\n",
    "model.add(ELU())\n",
    "# do not put activation at the end because we want to exact output, not a class identifier\n",
    "model.add(Dense(3, name = 'output', kernel_initializer = 'he_normal'))\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = adam, loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=5, padding=\"same\",input_shape=X[0].shape, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(Conv2D(128, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(256, kernel_size=3, padding=\"valid\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'  ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=50, activation='relu'  ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(units=10, activation='relu'  ))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3, name = 'output'))\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer = adam, loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7095, 30942]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-ffcac9623de2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7095, 30942]"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(np.array(X), np.array(y), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4753 samples, validate on 2342 samples\n",
      "Epoch 1/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1922 - val_loss: 8.9553\n",
      "Epoch 2/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1588 - val_loss: 8.7314\n",
      "Epoch 3/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1922 - val_loss: 8.7436\n",
      "Epoch 4/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1782 - val_loss: 8.9038\n",
      "Epoch 5/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1669 - val_loss: 8.7169\n",
      "Epoch 6/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1841 - val_loss: 8.7640\n",
      "Epoch 7/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1668 - val_loss: 8.6771\n",
      "Epoch 8/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1688 - val_loss: 8.6777\n",
      "Epoch 9/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1733 - val_loss: 8.7163\n",
      "Epoch 10/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1971 - val_loss: 8.9234\n",
      "Epoch 11/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1694 - val_loss: 8.7131\n",
      "Epoch 12/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 1.7866 - val_loss: 8.9581\n",
      "Epoch 13/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1550 - val_loss: 8.7483\n",
      "Epoch 14/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1038 - val_loss: 8.7899\n",
      "Epoch 15/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1237 - val_loss: 8.7544\n",
      "Epoch 16/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1384 - val_loss: 8.9556\n",
      "Epoch 17/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1420 - val_loss: 8.8668\n",
      "Epoch 18/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1321 - val_loss: 8.7713\n",
      "Epoch 19/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1387 - val_loss: 9.0941\n",
      "Epoch 20/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1305 - val_loss: 8.6690\n",
      "Epoch 21/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1323 - val_loss: 8.7181\n",
      "Epoch 22/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1239 - val_loss: 8.6838\n",
      "Epoch 23/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1315 - val_loss: 8.7312\n",
      "Epoch 24/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1195 - val_loss: 8.8273\n",
      "Epoch 25/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1335 - val_loss: 8.8309\n",
      "Epoch 26/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1343 - val_loss: 8.6753\n",
      "Epoch 27/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1440 - val_loss: 8.5956\n",
      "Epoch 28/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1088 - val_loss: 8.7659\n",
      "Epoch 29/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 4.1188 - val_loss: 8.9050\n",
      "Epoch 30/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1833 - val_loss: 8.7394\n",
      "Epoch 31/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1169 - val_loss: 8.8254\n",
      "Epoch 32/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1160 - val_loss: 8.7771\n",
      "Epoch 33/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1233 - val_loss: 8.6437\n",
      "Epoch 34/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1327 - val_loss: 8.7637\n",
      "Epoch 35/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1264 - val_loss: 8.6753\n",
      "Epoch 36/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1456 - val_loss: 9.4861\n",
      "Epoch 37/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1409 - val_loss: 8.5954\n",
      "Epoch 38/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0965 - val_loss: 8.7044\n",
      "Epoch 39/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1112 - val_loss: 8.7859\n",
      "Epoch 40/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1206 - val_loss: 8.6371\n",
      "Epoch 41/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1792 - val_loss: 8.7038\n",
      "Epoch 42/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0953 - val_loss: 8.7216\n",
      "Epoch 43/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1487 - val_loss: 8.7518\n",
      "Epoch 44/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1101 - val_loss: 8.7215\n",
      "Epoch 45/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1003 - val_loss: 8.7427\n",
      "Epoch 46/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1174 - val_loss: 8.7124\n",
      "Epoch 47/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1138 - val_loss: 8.7187\n",
      "Epoch 48/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1095 - val_loss: 8.8776\n",
      "Epoch 49/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1080 - val_loss: 8.6712\n",
      "Epoch 50/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1107 - val_loss: 8.6656\n",
      "Epoch 51/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1066 - val_loss: 8.9454\n",
      "Epoch 52/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1129 - val_loss: 8.7166\n",
      "Epoch 53/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0911 - val_loss: 8.7948\n",
      "Epoch 54/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1078 - val_loss: 8.6402\n",
      "Epoch 55/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1082 - val_loss: 8.7785\n",
      "Epoch 56/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1346 - val_loss: 8.6782\n",
      "Epoch 57/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0935 - val_loss: 8.7160\n",
      "Epoch 58/100\n",
      "4753/4753 [==============================] - 59s 13ms/step - loss: 0.0977 - val_loss: 8.8811\n",
      "Epoch 59/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1620 - val_loss: 8.7422\n",
      "Epoch 60/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1086 - val_loss: 8.7176\n",
      "Epoch 61/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0851 - val_loss: 8.7639\n",
      "Epoch 62/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0980 - val_loss: 8.8035\n",
      "Epoch 63/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1514 - val_loss: 8.7651\n",
      "Epoch 64/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0826 - val_loss: 8.8871\n",
      "Epoch 65/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0878 - val_loss: 8.7434\n",
      "Epoch 66/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1191 - val_loss: 8.8050\n",
      "Epoch 67/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0908 - val_loss: 8.7444\n",
      "Epoch 68/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0855 - val_loss: 8.7033\n",
      "Epoch 69/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0866 - val_loss: 8.7539\n",
      "Epoch 70/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0888 - val_loss: 8.7131\n",
      "Epoch 71/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0852 - val_loss: 8.7745\n",
      "Epoch 72/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0843 - val_loss: 8.5842\n",
      "Epoch 73/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0868 - val_loss: 8.6452\n",
      "Epoch 74/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0861 - val_loss: 8.8268\n",
      "Epoch 75/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0865 - val_loss: 8.8472\n",
      "Epoch 76/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0844 - val_loss: 8.7563\n",
      "Epoch 77/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0847 - val_loss: 8.7993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0804 - val_loss: 9.0385\n",
      "Epoch 79/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0844 - val_loss: 8.7965\n",
      "Epoch 80/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0857 - val_loss: 8.7222\n",
      "Epoch 81/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0710 - val_loss: 8.7035\n",
      "Epoch 82/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1525 - val_loss: 8.9047\n",
      "Epoch 83/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0828 - val_loss: 8.7956\n",
      "Epoch 84/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0599 - val_loss: 8.7818\n",
      "Epoch 85/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0797 - val_loss: 8.6938\n",
      "Epoch 86/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0840 - val_loss: 8.8102\n",
      "Epoch 87/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0809 - val_loss: 8.7239\n",
      "Epoch 88/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0810 - val_loss: 8.7783\n",
      "Epoch 89/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0790 - val_loss: 8.8036\n",
      "Epoch 90/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0716 - val_loss: 8.7880\n",
      "Epoch 91/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0811 - val_loss: 8.7243\n",
      "Epoch 92/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0772 - val_loss: 8.8187\n",
      "Epoch 93/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.1311 - val_loss: 8.7047\n",
      "Epoch 94/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0650 - val_loss: 8.6472\n",
      "Epoch 95/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0648 - val_loss: 8.8803\n",
      "Epoch 96/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0761 - val_loss: 8.7436\n",
      "Epoch 97/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0729 - val_loss: 8.7795\n",
      "Epoch 98/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0744 - val_loss: 8.7391\n",
      "Epoch 99/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0737 - val_loss: 8.8589\n",
      "Epoch 100/100\n",
      "4753/4753 [==============================] - 59s 12ms/step - loss: 0.0726 - val_loss: 8.7506\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val,y_val), epochs=100, verbose = 1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('nvidia.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_3 (Lambda)            (None, 180, 270, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 88, 133, 24)       1824      \n",
      "_________________________________________________________________\n",
      "elu_17 (ELU)                 (None, 88, 133, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 42, 65, 36)        21636     \n",
      "_________________________________________________________________\n",
      "elu_18 (ELU)                 (None, 42, 65, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 19, 31, 48)        43248     \n",
      "_________________________________________________________________\n",
      "elu_19 (ELU)                 (None, 19, 31, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 19, 31, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 17, 29, 64)        27712     \n",
      "_________________________________________________________________\n",
      "elu_20 (ELU)                 (None, 17, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 15, 27, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25920)             0         \n",
      "_________________________________________________________________\n",
      "elu_21 (ELU)                 (None, 25920)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 100)               2592100   \n",
      "_________________________________________________________________\n",
      "elu_22 (ELU)                 (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "elu_23 (ELU)                 (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "elu_24 (ELU)                 (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 2,729,041\n",
      "Trainable params: 2,729,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(np.array(X_train[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.006464</td>\n",
       "      <td>0.354181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.005117</td>\n",
       "      <td>0.042577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000647</td>\n",
       "      <td>0.011007</td>\n",
       "      <td>17.231133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000773</td>\n",
       "      <td>-0.010612</td>\n",
       "      <td>15.794473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.005034</td>\n",
       "      <td>2.012941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000497</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>20.340448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.005117</td>\n",
       "      <td>0.042579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.005118</td>\n",
       "      <td>0.042588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.001191</td>\n",
       "      <td>-0.015986</td>\n",
       "      <td>12.352467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000104</td>\n",
       "      <td>-0.003252</td>\n",
       "      <td>23.333912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1          2\n",
       "0  0.000069 -0.006464   0.354181\n",
       "1  0.000059 -0.005117   0.042577\n",
       "2 -0.000647  0.011007  17.231133\n",
       "3  0.000773 -0.010612  15.794473\n",
       "4  0.000154 -0.005034   2.012941\n",
       "5 -0.000497  0.007279  20.340448\n",
       "6  0.000059 -0.005117   0.042579\n",
       "7  0.000059 -0.005118   0.042588\n",
       "8  0.001191 -0.015986  12.352467\n",
       "9  0.000104 -0.003252  23.333912"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>8.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>19.360001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>19.469999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>18.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>2.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000149</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>16.879999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.000097</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>23.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0  0.000003  0.000007  0.480000\n",
       "1 -0.000004 -0.000115  8.370000\n",
       "2 -0.000126 -0.000156 19.360001\n",
       "3 -0.000147 -0.000132 19.469999\n",
       "4 -0.000003 -0.000006  1.200000\n",
       "5 -0.000016  0.000202 18.150000\n",
       "6  0.000015 -0.000014  2.060000\n",
       "7  0.000000 -0.000000  0.000000\n",
       "8 -0.000149  0.000030 16.879999\n",
       "9 -0.000097  0.000246 23.570000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "pd.DataFrame(y_train[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
